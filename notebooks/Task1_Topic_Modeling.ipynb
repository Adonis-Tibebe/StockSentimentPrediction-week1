{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Headlines Topic Modeling Analysis\n",
    "\n",
    "This notebook focuses on analyzing news headlines using Natural Language Processing (NLP) to:\n",
    "1. Identify common keywords and phrases\n",
    "2. Extract significant events and topics\n",
    "3. Track how topics evolve over time\n",
    "\n",
    "We'll use Latent Dirichlet Allocation (LDA) combined with specific event detection to understand what our news headlines are discussing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.topic_modeling import (\n",
    "    make_vectorizer,\n",
    "    build_dtm,\n",
    "    run_lda,\n",
    "    top_keywords_per_topic,\n",
    "    get_document_topics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "We'll use the cleaned news headlines dataset that we prepared in our EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7261 headlines\n",
      "\n",
      "Sample Headlines:\n",
      "[\"IVP, Sapphire Ventures Lead $100M Series E In CircleCI's Leading Software Solution\", \"Benzinga's Top Upgrades, Downgrades For November 16, 2018\", \"Baird Reiterates Outperform On Tesla As Firm Notes 'Headline cash balance ($5B) and cash generation ($614M) numbers were extremely favorable, in our view, and should support future growth investments'\", 'AMD, Texas Instruments See Short Interest Surge', \"Trading 212 Takes On Disciplined Investing With 'Next Generation Product'\"]\n"
     ]
    }
   ],
   "source": [
    "cleaned_filtered_data = pd.read_csv(\"../Data/cleaned/cleaned_filtered_news.csv\")\n",
    "print(f\"Loaded {len(cleaned_filtered_data)} headlines\")\n",
    "\n",
    "# Display sample headlines\n",
    "print(\"\\nSample Headlines:\")\n",
    "print(cleaned_filtered_data['headline'].sample(5).to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Detection Framework\n",
    "\n",
    "Before applying topic modeling, we'll first look for specific, important events in our headlines.\n",
    "This helps us identify concrete instances of significant events like \"FDA approval\" or \"price target changes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Headlines for Specific Events:\n",
      "\n",
      "Frequency of Specific Events:\n",
      "price_targets: 775 headlines\n",
      "fda_related: 0 headlines\n",
      "earnings: 26 headlines\n",
      "leadership: 129 headlines\n",
      "product: 172 headlines\n",
      "\n",
      "Example Headlines by Event Type:\n",
      "\n",
      "Price Targets:\n",
      "- UBS Maintains Buy on NVIDIA, Raises Price Target to $330\n",
      "- Credit Suisse Maintains Outperform on Amazon.com, Lowers Price Target to $2760\n",
      "- Jefferies Maintains Buy on Tesla, Raises Price Target to $400\n",
      "\n",
      "Fda Related:\n",
      "\n",
      "Earnings:\n",
      "- Nvidia Q1 Earnings Preview: Data Center, Gaming Inventory In Focus Amid Fundamental Uncertainties\n",
      "- AMD Earnings Preview: A Look At What Might Be Expected For The Chipmakers' Q2 Results\n",
      "- Nvidia Q3 Earnings Preview: Analysts Forecast Data Center, Gaming, Automotive Performance\n",
      "\n",
      "Leadership:\n",
      "- Did Alphabet's CEO Shuffle Come As A Surprise?\n",
      "- UPDATE: Nomura On Alphabet Notes 'and management noted the first two months of the quarter were strong followed by a significant slowdown in advertising revenue in March (consistent with SNAP's commentary last week'\n",
      "- Tesla CEO Musk Says Other Three Officers Should Be Charged In Floyd's Murder Case\n",
      "\n",
      "Product:\n",
      "- 'Amazon launches its first big-budget game, a shooter called Crucible' -Tweet From CNBC\n",
      "- Zoom Unveils Version 5 With Updated Security Measures Following Backlash\n",
      "- Activision Blizzard Announces Google Cloud Will Serve As Preferred Provider For Co., Youtube Will Serve As Its Exclusive Streaming Partner Worldwide, Excluding China\n"
     ]
    }
   ],
   "source": [
    "# Define specific events to track\n",
    "key_events = {\n",
    "    'price_targets': ['price target', 'raises target', 'lowers target', 'upgrades', 'downgrades'],\n",
    "    'fda_related': ['fda approval', 'fda clears', 'clinical trial', 'drug approval'],\n",
    "    'earnings': ['beats earnings', 'misses earnings', 'earnings preview', 'quarterly results'],\n",
    "    'leadership': ['ceo', 'executive changes', 'board member', 'management'],\n",
    "    'product': ['launches', 'announces', 'unveils', 'releases']\n",
    "}\n",
    "\n",
    "# Analyze headlines for specific events\n",
    "print(\"Analyzing Headlines for Specific Events:\")\n",
    "event_counts = {event: 0 for event in key_events}\n",
    "headline_events = []\n",
    "\n",
    "for headline in cleaned_filtered_data['headline']:\n",
    "    headline_lower = headline.lower()\n",
    "    found_events = []\n",
    "    \n",
    "    for event, phrases in key_events.items():\n",
    "        if any(phrase in headline_lower for phrase in phrases):\n",
    "            event_counts[event] += 1\n",
    "            found_events.append(event)\n",
    "    \n",
    "    headline_events.append(found_events)\n",
    "\n",
    "# Add events to dataframe\n",
    "cleaned_filtered_data['specific_events'] = headline_events\n",
    "\n",
    "# Show event statistics\n",
    "print(\"\\nFrequency of Specific Events:\")\n",
    "for event, count in event_counts.items():\n",
    "    print(f\"{event}: {count} headlines\")\n",
    "\n",
    "# Show example headlines for each event type\n",
    "print(\"\\nExample Headlines by Event Type:\")\n",
    "for event in key_events:\n",
    "    event_headlines = cleaned_filtered_data[\n",
    "        cleaned_filtered_data['specific_events'].apply(lambda x: event in x)\n",
    "    ]['headline'].sample(min(3, event_counts[event]))\n",
    "    \n",
    "    print(f\"\\n{event.replace('_', ' ').title()}:\")\n",
    "    for headline in event_headlines:\n",
    "        print(f\"- {headline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Analysis\n",
    "\n",
    "Now we'll use LDA to discover broader themes and patterns in our headlines.\n",
    "This will help us understand the general topics being discussed, beyond specific events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting headlines to numerical format...\n",
      "\n",
      "Discovering topics...\n",
      "\n",
      "Discovered Topics:\n",
      "\n",
      "Topic 1:\n",
      "Keywords: tesla, biggest, changes, musk, price, elon, electrek, target, model, 10, says, china, electric, production, friday\n",
      "\n",
      "Topic 2:\n",
      "Keywords: trade, tesla, china, devices, google, says, advanced, purchases, etf, huge, micro, amazon, car, new, share\n",
      "\n",
      "Topic 3:\n",
      "Keywords: nvidia, citron, tesla, goldman, deutsche, services, graphics, says, amd, left, bank, cramer, sachs, communication, new\n",
      "\n",
      "Topic 4:\n",
      "Keywords: upgrades, downgrades, nvidia, benzinga, morgan, stanley, buy, pt, bank, hold, initiates, coverage, america, 00, corporation\n",
      "\n",
      "Topic 5:\n",
      "Keywords: tesla, street, model, google, nvidia, earnings, investor, year, wall, deliveries, movement, semiconductor, coronavirus, index, starts\n",
      "\n",
      "Topic 6:\n",
      "Keywords: media, social, google, cloud, dow, nvidia, crude, etf, trump, gaming, video, executive, games, house, afternoon\n",
      "\n",
      "Topic 7:\n",
      "Keywords: target, price, maintains, raises, nvidia, buy, outperform, lowers, capital, overweight, tesla, morgan, pt, update, neutral\n",
      "\n",
      "Topic 8:\n",
      "Keywords: session, moving, stocks, pre, market, day, friday, thursday, mid, tuesday, cyclical, consumer, wednesday, gainers, hours\n",
      "\n",
      "Topic 9:\n",
      "Keywords: nvidia, driving, ai, self, report, data, autonomous, competition, google, chip, apple, platform, cloud, new, says\n",
      "\n",
      "Topic 10:\n",
      "Keywords: watch, earnings, vs, stocks, 2019, morning, option, 10, sales, benzinga, nvidia, q1, alert, pro, scheduled\n",
      "\n",
      "Topic 11:\n",
      "Keywords: shares, trading, higher, stock, lower, companies, futures, markets, peek, semiconductor, amid, coronavirus, ahead, market, economic\n",
      "\n",
      "Topic 12:\n",
      "Keywords: week, 52, highs, hit, stocks, etfs, earnings, losers, 13, 2015, new, automotive, worth, tech, thursday\n",
      "\n",
      "Topic 13:\n",
      "Keywords: picks, money, fast, barron, pans, tesla, 2012, nvidia, traders, ideas, auto, stock, launches, lows, new\n",
      "\n",
      "Topic 14:\n",
      "Keywords: bears, bulls, apple, week, amazon, boeing, tesla, edge, netflix, microsoft, covid, says, 19, nvidia, buffett\n",
      "\n",
      "Topic 15:\n",
      "Keywords: nvidia, amd, intel, shares, earnings, hitting, google, q4, following, guidance, says, shows, upside, stake, tesla\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert headlines to numerical format\n",
    "print(\"Converting headlines to numerical format...\")\n",
    "vectorizer = make_vectorizer(method='tfidf', max_features=5000)\n",
    "dtm, feature_names = build_dtm(cleaned_filtered_data['headline'].tolist(), vectorizer)\n",
    "\n",
    "# Step 2: Run LDA to discover topics\n",
    "print(\"\\nDiscovering topics...\")\n",
    "n_topics = 15  # Number of topics to discover\n",
    "lda_model = run_lda(dtm, num_topics=n_topics)\n",
    "\n",
    "# Step 3: Get the main words for each topic\n",
    "topics = top_keywords_per_topic(lda_model, feature_names, n_top=15)\n",
    "\n",
    "# Print discovered topics\n",
    "print(\"\\nDiscovered Topics:\")\n",
    "for idx, topic_words in enumerate(topics):\n",
    "    print(f\"\\nTopic {idx + 1}:\")\n",
    "    print(f\"Keywords: {', '.join(topic_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Assignment Analysis\n",
    "\n",
    "Let's examine how these topics appear in our headlines and how they relate to our specific events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Headlines with Topics and Events:\n",
      "\n",
      "Headline: Shares of several semiconductor companies are trading higher following a strong Q2 earnings report from Micron.\n",
      "Assigned Topics: [11]\n",
      "Topic Keywords:\n",
      "- Topic 11: shares, trading, higher, stock, lower\n",
      "\n",
      "Headline: Mellanox Shares Volatile Over Last Few Mins. On Volume Spike; Hearing Capitol Forum Says Deal Approval 'In Trouble,' Recent Talks Failed To Address Objections\n",
      "Assigned Topics: [1]\n",
      "Topic Keywords:\n",
      "- Topic 1: tesla, biggest, changes, musk, price\n",
      "\n",
      "Headline: Today's Pickup: Idelic Integrates Samsara ELD, Camera Data Into Platform\n",
      "Assigned Topics: [9]\n",
      "Topic Keywords:\n",
      "- Topic 9: nvidia, driving, ai, self, report\n",
      "\n",
      "Headline: Shares of several semiconductor companies are trading higher. Strength potentially related to earnings from notable names in the space this week as well as overall market strength amid a rebound in oil.\n",
      "Assigned Topics: [11]\n",
      "Topic Keywords:\n",
      "- Topic 11: shares, trading, higher, stock, lower\n",
      "\n",
      "Headline: KrebsOnSecurity's Brian Krebs Tweets: 'Heads up gamers: Nvidia discloses password breach. Change 'em, and if you used elsewhere (like email) change that http://ow.ly/GkZOi'\n",
      "Assigned Topics: [6]\n",
      "Topic Keywords:\n",
      "- Topic 6: media, social, google, cloud, dow\n",
      "\n",
      "Topic Assignment Statistics:\n",
      "Headlines with single topic: 6268\n",
      "Headlines with multiple topics: 7261\n"
     ]
    }
   ],
   "source": [
    "# Assign topics to headlines\n",
    "doc_topics = get_document_topics(lda_model, dtm)\n",
    "cleaned_filtered_data['topics'] = doc_topics\n",
    "\n",
    "# Show example headlines with their topics and events\n",
    "print(\"Example Headlines with Topics and Events:\")\n",
    "for _, row in cleaned_filtered_data.sample(5).iterrows():\n",
    "    print(f\"\\nHeadline: {row['headline']}\")\n",
    "    print(f\"Assigned Topics: {[i+1 for i in row['topics']]}\")\n",
    "    print(\"Topic Keywords:\")\n",
    "    for topic_idx in row['topics']:\n",
    "        print(f\"- Topic {topic_idx + 1}: {', '.join(topics[topic_idx][:5])}\")\n",
    "    if row['specific_events']:\n",
    "        print(f\"Specific Events Found: {row['specific_events']}\")\n",
    "\n",
    "# Show topic assignment statistics\n",
    "topic_counts = cleaned_filtered_data['topics'].apply(len).value_counts()\n",
    "print(\"\\nTopic Assignment Statistics:\")\n",
    "print(f\"Headlines with single topic: {topic_counts[1]}\")\n",
    "print(f\"Headlines with multiple topics: {sum(topic_counts[topic_counts > 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Analysis\n",
    "\n",
    "Finally, let's analyze how our topics and events evolve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic and Event Evolution by Company:\n",
      "\n",
      "MSF:\n",
      "\n",
      "Year 2010:\n",
      "Topics: [10]\n",
      "\n",
      "Year 2016:\n",
      "Topics: [5]\n",
      "\n",
      "NVDA:\n",
      "\n",
      "Year 2011:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['earnings', 'leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2012:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2013:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['earnings', 'leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2014:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['product', 'price_targets']\n",
      "\n",
      "Year 2015:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2016:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['earnings', 'leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2017:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['earnings', 'leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2018:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['earnings', 'leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2019:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['earnings', 'leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2020:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['leadership', 'product', 'price_targets']\n",
      "\n",
      "GOOG:\n",
      "\n",
      "Year 2018:\n",
      "Topics: [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 14]\n",
      "Specific Events: ['leadership']\n",
      "\n",
      "Year 2019:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['earnings', 'leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2020:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['leadership', 'product', 'price_targets']\n",
      "\n",
      "TSLA:\n",
      "\n",
      "Year 2019:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['leadership', 'product', 'price_targets']\n",
      "\n",
      "Year 2020:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['earnings', 'leadership', 'product', 'price_targets']\n",
      "\n",
      "FB:\n",
      "\n",
      "Year 2020:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['leadership', 'product', 'price_targets']\n",
      "\n",
      "AAPL:\n",
      "\n",
      "Year 2020:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['leadership', 'product', 'price_targets']\n",
      "\n",
      "AMZN:\n",
      "\n",
      "Year 2020:\n",
      "Topics: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Specific Events: ['leadership', 'product', 'price_targets']\n"
     ]
    }
   ],
   "source": [
    "# Add year information\n",
    "cleaned_filtered_data['year'] = pd.to_datetime(cleaned_filtered_data['date']).dt.year\n",
    "\n",
    "# Analyze topics and events over time\n",
    "print(\"Topic and Event Evolution by Company:\")\n",
    "for company in cleaned_filtered_data['stock'].unique():\n",
    "    company_data = cleaned_filtered_data[cleaned_filtered_data['stock'] == company]\n",
    "    print(f\"\\n{company}:\")\n",
    "    \n",
    "    # Group by year\n",
    "    yearly_data = company_data.groupby('year')\n",
    "    \n",
    "    for year, year_data in yearly_data:\n",
    "        print(f\"\\nYear {year}:\")\n",
    "        # Show topics\n",
    "        year_topics = set([topic for topics in year_data['topics'] for topic in topics])\n",
    "        print(\"Topics:\", [i+1 for i in year_topics])\n",
    "        \n",
    "        # Show specific events\n",
    "        year_events = set([event for events in year_data['specific_events'] for event in events])\n",
    "        if year_events:\n",
    "            print(\"Specific Events:\", list(year_events))\n",
    "\n",
    "# Save results\n",
    "cleaned_filtered_data.to_csv(\"../Data/cleaned/analyzed/tech_news_with_topics_and_events.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock',\n",
       "       'specific_events', 'topics', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_filtered_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
